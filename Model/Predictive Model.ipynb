{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Display multiple outputs from one single cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading positive and negative events\n",
    "positive = pd.read_csv(\"Data/NY_Accidents_June20.csv\")\n",
    "negative = pd.read_csv(\"Data/NY_Negatives_June20.csv\")\n",
    "\n",
    "# Assign label 'Accident' to each event\n",
    "positive['Accident'] = 1\n",
    "negative['Accident'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Source', 'TMC', 'Severity', 'Start_Time',\n",
       "       'End_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Description',\n",
       "       'Number', 'Street', 'Side', 'City', 'County', 'State', 'Zipcode',\n",
       "       'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight', 'acc_year', 'acc_month', 'acc_hr_day',\n",
       "       'new_date', 'day_name', 'Accident'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider using the following line of code to remove all nan entries.\n",
    "# dataset = dataset.dropna()\n",
    "\n",
    "positive = positive[~positive['Temperature(F)'].isna()]\n",
    "positive = positive[~positive['Weather_Condition'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8135, 54)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Source', 'TMC', 'Severity', 'Start_Time',\n",
       "       'End_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Description',\n",
       "       'Number', 'Street', 'Side', 'City', 'County', 'State', 'Zipcode',\n",
       "       'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight', 'acc_year', 'acc_month', 'acc_hr_day',\n",
       "       'new_date', 'day_name', 'Accident'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.shape\n",
    "negative.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Working Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this segment, we will create a working dataset containing equal number of both positive and negative samples.  We will then do a train/test split on this new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "random_seed = 42\n",
    "test_size = 0.2  # 80% train, 20% test\n",
    "features = ['Temperature(F)',\n",
    "            'Weather_Condition', \n",
    "            'Sunrise_Sunset', \n",
    "            'Civil_Twilight', \n",
    "            'Nautical_Twilight',\n",
    "            'Astronomical_Twilight',\n",
    "            'acc_month',\n",
    "            'acc_hr_day',\n",
    "            'day_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinhsia/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Create working dataset\n",
    "# 1. sample equal number of positive cases from dataset 'negative' without replacement\n",
    "# 2. merge with dataset 'positive'\n",
    "# 3. pull X [features] and Y [label], which is the new parameter 'Accident' in Section 1\n",
    "# 4. one-hot encode 'object' features\n",
    "# 5. shuffle the new dataset\n",
    "# 6. train/test split the dataset\n",
    "\n",
    "# 1\n",
    "# temp = negative.sample(n=positive.shape[0], random_state=random_seed, replace=True).copy(deep=True)\n",
    "temp = negative.sample(n=positive.shape[0], random_state=random_seed, replace=False)\n",
    "\n",
    "# 2\n",
    "data = pd.concat([positive, temp], axis=0, ignore_index=True)\n",
    "\n",
    "# 3\n",
    "X, y = data[features], data.Accident\n",
    "X.acc_month = X.acc_month.astype('object')\n",
    "X.acc_hr_day = X.acc_hr_day.astype('object')\n",
    "\n",
    "# 4\n",
    "X = pd.get_dummies(X,drop_first=True)\n",
    "\n",
    "# 5\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X.iloc[shuffle], y.iloc[shuffle]\n",
    "\n",
    "# 6\n",
    "# n = round(train_test_split_ratio * X.shape[0])\n",
    "# train_data, train_labels = X.iloc[:n], Y.iloc[:n]\n",
    "# test_data, test_labels = X.iloc[n:], Y.iloc[n:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49170251997541486"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(random_state=random_seed).fit(X_train, y_train)\n",
    "logit_pred = logit.predict(X_test)\n",
    "logit_score = logit.score(X_test, y_test)\n",
    "logit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3869084204056546"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state=random_seed).fit(X_train, y_train)\n",
    "DT_pred = DT.predict(X_test)\n",
    "DT_score = DT.score(X_test, y_test)\n",
    "DT_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4794099569760295"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "MLP_pred = MLP.predict(X_test)\n",
    "MLP_score = MLP.score(X_test, y_test)\n",
    "MLP_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Keras Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature(F)</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>57.597308</td>\n",
       "      <td>17.397745</td>\n",
       "      <td>3.9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition_Cloudy</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.080455</td>\n",
       "      <td>0.272004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition_Cloudy / Windy</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition_Fair</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.177505</td>\n",
       "      <td>0.382107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition_Fair / Windy</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>0.247663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.079902</td>\n",
       "      <td>0.271149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.173940</td>\n",
       "      <td>0.379069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.170191</td>\n",
       "      <td>0.375812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_name_Wednesday</th>\n",
       "      <td>16270.0</td>\n",
       "      <td>0.166994</td>\n",
       "      <td>0.372982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    count       mean        std  min   25%  \\\n",
       "Temperature(F)                    16270.0  57.597308  17.397745  3.9  44.0   \n",
       "Weather_Condition_Cloudy          16270.0   0.080455   0.272004  0.0   0.0   \n",
       "Weather_Condition_Cloudy / Windy  16270.0   0.000246   0.015678  0.0   0.0   \n",
       "Weather_Condition_Fair            16270.0   0.177505   0.382107  0.0   0.0   \n",
       "Weather_Condition_Fair / Windy    16270.0   0.000061   0.007840  0.0   0.0   \n",
       "...                                   ...        ...        ...  ...   ...   \n",
       "day_name_Saturday                 16270.0   0.065642   0.247663  0.0   0.0   \n",
       "day_name_Sunday                   16270.0   0.079902   0.271149  0.0   0.0   \n",
       "day_name_Thursday                 16270.0   0.173940   0.379069  0.0   0.0   \n",
       "day_name_Tuesday                  16270.0   0.170191   0.375812  0.0   0.0   \n",
       "day_name_Wednesday                16270.0   0.166994   0.372982  0.0   0.0   \n",
       "\n",
       "                                   50%   75%   max  \n",
       "Temperature(F)                    57.9  72.0  95.0  \n",
       "Weather_Condition_Cloudy           0.0   0.0   1.0  \n",
       "Weather_Condition_Cloudy / Windy   0.0   0.0   1.0  \n",
       "Weather_Condition_Fair             0.0   0.0   1.0  \n",
       "Weather_Condition_Fair / Windy     0.0   0.0   1.0  \n",
       "...                                ...   ...   ...  \n",
       "day_name_Saturday                  0.0   0.0   1.0  \n",
       "day_name_Sunday                    0.0   0.0   1.0  \n",
       "day_name_Thursday                  0.0   0.0   1.0  \n",
       "day_name_Tuesday                   0.0   0.0   1.0  \n",
       "day_name_Wednesday                 0.0   0.0   1.0  \n",
       "\n",
       "[67 rows x 8 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.7652473e+01 7.9901658e-02 3.0731407e-04 1.7739704e-01 7.6828517e-05\n",
      " 7.3755379e-03 1.2446220e-02 6.0694530e-03 7.6828519e-04 2.3048556e-04\n",
      " 3.0731407e-04 6.2154271e-02 3.8414259e-04 3.9182543e-03 3.0731407e-04\n",
      " 8.4588200e-02 1.4643516e-01 5.6161646e-02 1.2446220e-02 2.3816841e-02\n",
      " 4.6097112e-04 3.8414259e-04 1.5365703e-04 2.7788875e-01 2.3240627e-01\n",
      " 1.8392748e-01 1.4566687e-01 7.6367550e-02 8.2360171e-02 9.9262446e-02\n",
      " 1.0840504e-01 1.0341118e-01 7.4523665e-02 7.7443145e-02 7.4754149e-02\n",
      " 7.9517514e-02 7.7289492e-02 7.3832206e-02 6.7609097e-03 6.0694530e-03\n",
      " 6.8377382e-03 1.8669330e-02 3.8337432e-02 6.6149354e-02 7.5983405e-02\n",
      " 7.0144437e-02 4.8555624e-02 6.1078671e-02 5.3626306e-02 4.9708053e-02\n",
      " 4.9631223e-02 5.7314076e-02 5.4701906e-02 6.6072524e-02 5.9004303e-02\n",
      " 5.2089736e-02 5.0015364e-02 3.6954518e-02 2.4277812e-02 1.8976644e-02\n",
      " 1.5596190e-02 1.7255685e-01 6.6379838e-02 7.7980943e-02 1.7624462e-01\n",
      " 1.7132759e-01 1.6633375e-01]\n"
     ]
    }
   ],
   "source": [
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__metaclass__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_inbound_node',\n",
       " '_add_state_variable',\n",
       " '_add_trackable',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_attribute_sentinel',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_broadcast_shape',\n",
       " '_build_input_shape',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_callable_losses',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_collect_input_masks',\n",
       " '_combiner',\n",
       " '_compute_dtype',\n",
       " '_dedup_weights',\n",
       " '_deferred_dependencies',\n",
       " '_dtype',\n",
       " '_dtype_defaulted_to_floatx',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_add_metric',\n",
       " '_eager_losses',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_flatten',\n",
       " '_gather_children_attribute',\n",
       " '_gather_layers',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_gather_unique_layers',\n",
       " '_get_call_arg_value',\n",
       " '_get_dataset_iterator',\n",
       " '_get_existing_metric',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_trainable_state',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_inbound_nodes',\n",
       " '_init_call_fn_args',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_spec',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_layers',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_no_dependency',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_preload_simple_restoration',\n",
       " '_previously_updated',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_restore_updates',\n",
       " '_self_name_based_restores',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_set_connectivity_metadata_',\n",
       " '_set_dtype_policy',\n",
       " '_set_mask_metadata',\n",
       " '_set_state_variables',\n",
       " '_set_trainable_state',\n",
       " '_setattr_tracking',\n",
       " '_should_compute_mask',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_stateful',\n",
       " '_supports_ragged_inputs',\n",
       " '_symbolic_add_metric',\n",
       " '_symbolic_call',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_updates',\n",
       " '_warn_about_input_casting',\n",
       " 'activity_regularizer',\n",
       " 'adapt',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'axis',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dynamic',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'losses',\n",
       " 'mean',\n",
       " 'metrics',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'set_weights',\n",
       " 'state_variables',\n",
       " 'stateful',\n",
       " 'submodules',\n",
       " 'supports_masking',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variables',\n",
       " 'variance',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[82.9  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.   0. ]]\n",
      "\n",
      "Normalized: [[ 1.46 -0.29 -0.02 -0.46 -0.01 -0.09 -0.11 -0.08 -0.03 -0.02 -0.02 -0.26\n",
      "  -0.02 -0.06 -0.02 -0.3  -0.41 -0.24 -0.11 -0.16 -0.02 -0.02 -0.01  1.61\n",
      "   1.82  2.11  2.42 -0.29 -0.3  -0.33 -0.35 -0.34 -0.28 -0.29  3.52 -0.29\n",
      "  -0.29 -0.28 -0.08 -0.08 -0.08 -0.14 -0.2  -0.27 -0.29 -0.27 -0.23 -0.26\n",
      "  -0.24 -0.23 -0.23 -0.25 -0.24 -0.27 -0.25 -0.23 -0.23 -0.2   6.34 -0.14\n",
      "  -0.13  2.19 -0.27 -0.29 -0.46 -0.45 -0.45]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(X_train[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "    \n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
